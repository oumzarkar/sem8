from keras.datasets import imdb: Imports the IMDb movie review dataset module from Keras.
(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = 10000): Loads the IMDb movie review dataset, separating it into training and testing sets. The num_words parameter specifies that only the top 10,000 most frequently occurring words will be kept in the dataset.
word_index = imdb.get_word_index(): Retrieves the word index from the IMDb dataset, which is a dictionary mapping words to their integer indices.
reverse_word_index = dict([(value, key) for (key, value) in word_index.items()]): Creates a reverse word index dictionary, mapping integer indices back to their corresponding words.
decoded_review = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[0]]): Decodes the first training review from its integer sequence representation back to words. The integer sequence is converted back to words using the reverse word index. The get method is used to retrieve words, and ? is used as the default value if a word is not found.
import numpy as np: Imports the NumPy library with the alias np, which is commonly used for numerical computing in Python.

def vectorize_sequences(sequences, dimension=10000):: Defines a function named vectorize_sequences that takes a list of sequences and converts them into a binary matrix representation.
results = np.zeros((len(sequences), dimension)): Creates an all-zero matrix of shape (len(sequences), 10000) using NumPy. This matrix will hold the vectorized representations of the sequences.
for i,sequence in enumerate(sequences):: Iterates over each sequence in the list of sequences, using the enumerate function to also track the index i.
results[i,sequence] = 1: Sets specific indices of the results matrix to 1s, indicating the presence of words from the sequences.
return results: Returns the binary matrix representation of the sequences.
X_train = vectorize_sequences(train_data): Vectorizes the training data using the vectorize_sequences function.
X_test = vectorize_sequences(test_data): Vectorizes the testing data using the vectorize_sequences function.

class_names = ['negative','positive']: Defines the class names for the binary classification problem.
y_train = np.asarray(train_labels).astype('float32'): Converts the training labels to a NumPy array and casts them to the float32 data type.
y_test = np.asarray(test_labels).astype('float32'): Converts the testing labels to a NumPy array and casts them to the float32 data type.

from keras import models: Imports the models module from Keras, which contains tools for building neural network models.
from keras import layers: Imports the layers module from Keras, which contains various types of layers that can be added to neural network models.

model = models.Sequential(): Initializes a sequential model, which is a linear stack of layers.
model.add(layers.Dense(16, activation='relu', input_shape=(10000,))): Adds a dense layer with 16 units and ReLU activation function to the model. The input_shape parameter specifies the shape of the input data.
model.add(layers.Dense(16, activation='relu')): Adds another dense layer with 16 units and ReLU activation function to the model.
model.add(layers.Dense(1, activation='sigmoid')): Adds the output layer with 1 unit and sigmoid activation function, which is suitable for binary classification.

from keras import optimizers: Imports the optimizers module from Keras, which contains optimization algorithms for training neural networks.
from keras import losses: Imports the losses module from Keras, which contains loss functions used to measure the performance of a model.
from keras import metrics: Imports the metrics module from Keras, which contains evaluation metrics for assessing model performance.

model.compile(optimizer=optimizers.RMSprop(learning_rate=0.001), loss=losses.binary_crossentropy, metrics=[metrics.binary_accuracy]): Compiles the model, specifying the RMSprop optimizer with a learning rate of 0.001, binary cross-entropy loss function, and binary accuracy as the evaluation metric.
X_val = X_train[:10000]: Creates a validation set X_val by taking the first 10,000 samples from the training data.
partial_X_train = X_train[10000:]: Creates a partial training set partial_X_train by excluding the first 10,000 samples from the training data.
y_val = y_train[:10000]: Creates a validation set y_val by taking the first 10,000 labels from the training labels.
partial_y_train = y_train[10000:]: Creates a partial training set partial_y_train by excluding the first 10,000 labels from the training labels.

history = model.fit(partial_X_train, partial_y_train, epochs=10, batch_size=512, validation_data=(X_val, y_val)): Trains the model using the partial training data (partial_X_train and partial_y_train) for 10 epochs with a batch size of 512. The validation data (X_val, y_val) is used for validation during training. The training history is stored in the history variable.

result = model.predict(np.expand_dims(X_test[19],axis=0)): Uses the trained model to predict the sentiment of the 20th testing example (X_test[19]). The np.expand_dims function is used to add an extra dimension to the input data since the model expects a batch dimension.
print(result,class_names[int(result[0]>0.5)]): Prints the predicted sentiment probability and the corresponding class label (either 'negative' or 'positive') based on whether the probability is greater than 0.5.

get_phrase = input("Enter: "): Prompts the user to enter a phrase for sentiment analysis.

vec_words = []: Initializes an empty list to store the vectorized representations of the words in the user-entered phrase.

for i in get_phrase.split(" "):: Iterates over each word in the user-entered phrase after splitting it by spaces.
vec_words.append(word_index[i.lower()]): Retrieves the integer index of each word from the word_index dictionary and appends it to the vec_words list. The .lower() method is used to convert each word to lowercase to match the keys in the word_index dictionary.
vec_words = vectorize_sequences(vec_words): Converts the list of word indices (vec_words) into a binary matrix representation using the vectorize_sequences function.
result = []: Initializes an empty list to store the sentiment predictions for each word in the user-entered phrase.

for j in range(len(vec_words)):: Iterates over each vectorized word in the binary matrix.
result99 = model.predict(np.expand_dims(vec_words[j],axis=0)): Predicts the sentiment of each word in the user-entered phrase using the trained model. The np.expand_dims function is used to add an extra dimension to the input data since the model expects a batch dimension.
result.append(class_names[int(result99[0]>0.5)]): Appends the predicted sentiment label ('negative' or 'positive') to the result list based on whether the predicted probability is greater than 0.5.
Finally, the code counts the number of 'negative' and 'positive' sentiments in the result list and prints the overall sentiment of the user-entered phrase based on the majority sentiment. If there are more occurrences of 'negative' sentiment, it prints "NEGATIVE", otherwise it prints "POSITIVE".
